{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "NUM_EPOCHS = 70\n",
    "INIT_LR = 5e-3\n",
    "COLORS = 1\n",
    "KERN = 3 \n",
    "\n",
    "#create an object of the sequential class\n",
    "model = Sequential()\n",
    "\n",
    "#Layer 1- add 2D convolutional layer to process the 2D input images. We have 32 output channels.\n",
    "#Next we have a 3x3 moving window (kernel_size) and declearing input shape is only reqired of the first layer.\n",
    "model.add(Conv2D(32, (KERN, KERN), input_shape = (64, 64, COLORS)))\n",
    "\n",
    "\n",
    "#add the pooling layer- here we don't need to declear weights or bias variables like in tflearn. Keras sorts that out for us.\n",
    "model.add(MaxPooling2D(pool_size = (2, 2), strides= (2,2))) #strides= x and y directions(2,2)\n",
    "#use rectified linear unit as activation function\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Layer 2\n",
    "model.add(Conv2D(32, (KERN, KERN)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#model.add(Conv2D(64, (KERN, KERN), activation='relu'))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#convert the pooled images into a 1D features vector\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "#initilize output layer\n",
    "model.add(Dense(6, activation = 'softmax')) #6 labels\n",
    "\n",
    "opt = SGD(lr=INIT_LR, momentum=0.9)\n",
    "#opt = 'adam'\n",
    "model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4872 images belonging to 6 classes.\n",
      "Found 659 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "train_datagen = ImageDataGenerator( #rescale = 1./255 \n",
    "featurewise_center=False, # set input mean to 0 over the dataset\n",
    "samplewise_center=False, # set each sample mean to 0\n",
    "featurewise_std_normalization=False, # divide inputs by std of the dataset\n",
    "samplewise_std_normalization=False, # divide each input by its std\n",
    "#zca_whitening=False, # apply ZCA whitening\n",
    "rotation_range=1, # randomly rotate images in the range (degrees, 0 to 180)\n",
    "width_shift_range=0.1, # randomly shift images horizontally (fraction of total width)\n",
    "height_shift_range=0.1, # randomly shift images vertically (fraction of total height)\n",
    "horizontal_flip=False, # randomly flip images\n",
    "vertical_flip=False) # randomly flip images\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator( #rescale = 1./255 \n",
    "#featurewise_center=False, # set input mean to 0 over the dataset\n",
    "samplewise_center=False, # set each sample mean to 0\n",
    "#featurewise_std_normalization=False, # divide inputs by std of the dataset\n",
    "samplewise_std_normalization=False, # divide each input by its std\n",
    "#zca_whitening=False, # apply ZCA whitening\n",
    "#rotation_range=1, # randomly rotate images in the range (degrees, 0 to 180)\n",
    "#width_shift_range=0.1, # randomly shift images horizontally (fraction of total width)\n",
    "#height_shift_range=0.1, # randomly shift images vertically (fraction of total height)\n",
    "#horizontal_flip=False, # randomly flip images\n",
    "vertical_flip=False) # randomly flip images\n",
    "#rescale = 1./255)\n",
    "\n",
    "td = 'Marcel-train'\n",
    "TRAIN_IMG_CNT = 4872\n",
    "#td = 'more-train'\n",
    "#TRAIN_IMG_CNT = 19488\n",
    "VALIDATION_CNT = 659\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(td, \n",
    "                                                 target_size = (64, 64), \n",
    "                                                 batch_size = batch_size,\n",
    "                                                 color_mode = 'grayscale',\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('Marcel-Test', \n",
    "                                            target_size = (64, 64), \n",
    "                                            batch_size = batch_size, \n",
    "                                            color_mode = 'grayscale',\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_decay(epoch):\n",
    "\t# initialize the maximum number of epochs, base learning rate,\n",
    "\t# and power of the polynomial\n",
    "\tmaxEpochs = NUM_EPOCHS\n",
    "\tbaseLR = INIT_LR\n",
    "\tpower = 1.0\n",
    " \n",
    "\t# compute the new learning rate based on polynomial decay\n",
    "\talpha = baseLR * (1 - (epoch / float(maxEpochs))) ** power\n",
    " \n",
    "\t# return the new learning rate\n",
    "\treturn alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop_monitor = EarlyStopping(patience = 5)\n",
    "callbacks = [\n",
    "    LearningRateScheduler(poly_decay),\n",
    "#            early_stop_monitor\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "305/304 [==============================] - 19s 62ms/step - loss: 1.4734 - acc: 0.3996 - val_loss: 2.0697 - val_acc: 0.2428\n",
      "Epoch 2/70\n",
      "305/304 [==============================] - 21s 70ms/step - loss: 1.2602 - acc: 0.4730 - val_loss: 1.9668 - val_acc: 0.2398\n",
      "Epoch 3/70\n",
      "305/304 [==============================] - 25s 83ms/step - loss: 1.1465 - acc: 0.5244 - val_loss: 1.7229 - val_acc: 0.3156\n",
      "Epoch 4/70\n",
      "305/304 [==============================] - 22s 73ms/step - loss: 1.0848 - acc: 0.5520 - val_loss: 1.6823 - val_acc: 0.3323\n",
      "Epoch 5/70\n",
      "305/304 [==============================] - 21s 69ms/step - loss: 0.9702 - acc: 0.6072 - val_loss: 2.0560 - val_acc: 0.3520\n",
      "Epoch 6/70\n",
      "305/304 [==============================] - 22s 71ms/step - loss: 0.8749 - acc: 0.6572 - val_loss: 2.5272 - val_acc: 0.3869\n",
      "Epoch 7/70\n",
      "305/304 [==============================] - 21s 68ms/step - loss: 0.7462 - acc: 0.7123 - val_loss: 1.3697 - val_acc: 0.5630\n",
      "Epoch 8/70\n",
      "305/304 [==============================] - 20s 65ms/step - loss: 0.6598 - acc: 0.7520 - val_loss: 1.3616 - val_acc: 0.5478\n",
      "Epoch 9/70\n",
      "305/304 [==============================] - 19s 62ms/step - loss: 0.5996 - acc: 0.7789 - val_loss: 1.5957 - val_acc: 0.5781\n",
      "Epoch 10/70\n",
      "305/304 [==============================] - 20s 66ms/step - loss: 0.5351 - acc: 0.8027 - val_loss: 1.3903 - val_acc: 0.5493\n",
      "Epoch 11/70\n",
      "305/304 [==============================] - 19s 61ms/step - loss: 0.4700 - acc: 0.8311 - val_loss: 0.9894 - val_acc: 0.6480\n",
      "Epoch 12/70\n",
      "305/304 [==============================] - 19s 63ms/step - loss: 0.4487 - acc: 0.8365 - val_loss: 1.2619 - val_acc: 0.6161\n",
      "Epoch 13/70\n",
      "305/304 [==============================] - 19s 61ms/step - loss: 0.3717 - acc: 0.8666 - val_loss: 1.6898 - val_acc: 0.5857\n",
      "Epoch 14/70\n",
      "305/304 [==============================] - 18s 60ms/step - loss: 0.3821 - acc: 0.8590 - val_loss: 1.2322 - val_acc: 0.6388\n",
      "Epoch 15/70\n",
      "305/304 [==============================] - 18s 60ms/step - loss: 0.3584 - acc: 0.8695 - val_loss: 1.4521 - val_acc: 0.6404\n",
      "Epoch 16/70\n",
      "305/304 [==============================] - 20s 66ms/step - loss: 0.3280 - acc: 0.8783 - val_loss: 1.3175 - val_acc: 0.6753\n",
      "Epoch 17/70\n",
      "305/304 [==============================] - 19s 62ms/step - loss: 0.3044 - acc: 0.8941 - val_loss: 1.0341 - val_acc: 0.6798\n",
      "Epoch 18/70\n",
      "305/304 [==============================] - 20s 66ms/step - loss: 0.2992 - acc: 0.8947 - val_loss: 1.3394 - val_acc: 0.6464\n",
      "Epoch 19/70\n",
      "305/304 [==============================] - 20s 65ms/step - loss: 0.2981 - acc: 0.8939 - val_loss: 1.4570 - val_acc: 0.6601\n",
      "Epoch 20/70\n",
      "305/304 [==============================] - 19s 63ms/step - loss: 0.2521 - acc: 0.9088 - val_loss: 0.9474 - val_acc: 0.6889\n",
      "Epoch 21/70\n",
      "305/304 [==============================] - 20s 64ms/step - loss: 0.2768 - acc: 0.9012 - val_loss: 1.5684 - val_acc: 0.6373\n",
      "Epoch 22/70\n",
      "305/304 [==============================] - 20s 66ms/step - loss: 0.2281 - acc: 0.9195 - val_loss: 1.1093 - val_acc: 0.7071\n",
      "Epoch 23/70\n",
      "305/304 [==============================] - 20s 66ms/step - loss: 0.2118 - acc: 0.9250 - val_loss: 1.7298 - val_acc: 0.6085\n",
      "Epoch 24/70\n",
      "305/304 [==============================] - 19s 61ms/step - loss: 0.2077 - acc: 0.9266 - val_loss: 1.9029 - val_acc: 0.6434\n",
      "Epoch 25/70\n",
      "305/304 [==============================] - 19s 64ms/step - loss: 0.2086 - acc: 0.9262 - val_loss: 1.1724 - val_acc: 0.7011\n",
      "Epoch 26/70\n",
      "305/304 [==============================] - 19s 63ms/step - loss: 0.2042 - acc: 0.9314 - val_loss: 2.0845 - val_acc: 0.6297\n",
      "Epoch 27/70\n",
      "305/304 [==============================] - 20s 65ms/step - loss: 0.1994 - acc: 0.9275 - val_loss: 1.1194 - val_acc: 0.7132\n",
      "Epoch 28/70\n",
      "305/304 [==============================] - 20s 65ms/step - loss: 0.1661 - acc: 0.9371 - val_loss: 1.5237 - val_acc: 0.6783\n",
      "Epoch 29/70\n",
      "305/304 [==============================] - 21s 68ms/step - loss: 0.1654 - acc: 0.9414 - val_loss: 1.7409 - val_acc: 0.6859\n",
      "Epoch 30/70\n",
      "305/304 [==============================] - 18s 59ms/step - loss: 0.1836 - acc: 0.9363 - val_loss: 1.2634 - val_acc: 0.7117\n",
      "Epoch 31/70\n",
      "305/304 [==============================] - 19s 61ms/step - loss: 0.1679 - acc: 0.9432 - val_loss: 1.2657 - val_acc: 0.7162\n",
      "Epoch 32/70\n",
      "305/304 [==============================] - 19s 61ms/step - loss: 0.1625 - acc: 0.9416 - val_loss: 1.0617 - val_acc: 0.7223\n",
      "Epoch 33/70\n",
      "305/304 [==============================] - 19s 63ms/step - loss: 0.1545 - acc: 0.9445 - val_loss: 1.6458 - val_acc: 0.6844\n",
      "Epoch 34/70\n",
      "305/304 [==============================] - 19s 63ms/step - loss: 0.1551 - acc: 0.9416 - val_loss: 1.4083 - val_acc: 0.7026\n",
      "Epoch 35/70\n",
      "305/304 [==============================] - 20s 66ms/step - loss: 0.1538 - acc: 0.9420 - val_loss: 1.5508 - val_acc: 0.6737\n",
      "Epoch 36/70\n",
      "305/304 [==============================] - 19s 61ms/step - loss: 0.1520 - acc: 0.9471 - val_loss: 1.2438 - val_acc: 0.7193\n",
      "Epoch 37/70\n",
      "305/304 [==============================] - 18s 59ms/step - loss: 0.1551 - acc: 0.9469 - val_loss: 1.1535 - val_acc: 0.7299\n",
      "Epoch 38/70\n",
      "305/304 [==============================] - 18s 59ms/step - loss: 0.1346 - acc: 0.9504 - val_loss: 1.4278 - val_acc: 0.7071\n",
      "Epoch 39/70\n",
      "305/304 [==============================] - 19s 62ms/step - loss: 0.1344 - acc: 0.9496 - val_loss: 1.6331 - val_acc: 0.6692\n",
      "Epoch 40/70\n",
      "305/304 [==============================] - 19s 61ms/step - loss: 0.1354 - acc: 0.9492 - val_loss: 1.4982 - val_acc: 0.6950\n",
      "Epoch 41/70\n",
      "305/304 [==============================] - 18s 58ms/step - loss: 0.1322 - acc: 0.9512 - val_loss: 1.5703 - val_acc: 0.6920\n",
      "Epoch 42/70\n",
      "305/304 [==============================] - 19s 63ms/step - loss: 0.1205 - acc: 0.9561 - val_loss: 1.0631 - val_acc: 0.7390\n",
      "Epoch 43/70\n",
      "305/304 [==============================] - 21s 68ms/step - loss: 0.1426 - acc: 0.9471 - val_loss: 1.5870 - val_acc: 0.6753\n",
      "Epoch 44/70\n",
      "305/304 [==============================] - 19s 61ms/step - loss: 0.1228 - acc: 0.9566 - val_loss: 1.4842 - val_acc: 0.6904\n",
      "Epoch 45/70\n",
      "305/304 [==============================] - 18s 60ms/step - loss: 0.1227 - acc: 0.9559 - val_loss: 1.4071 - val_acc: 0.7026\n",
      "Epoch 46/70\n",
      "305/304 [==============================] - 20s 66ms/step - loss: 0.1078 - acc: 0.9607 - val_loss: 1.2123 - val_acc: 0.7253\n",
      "Epoch 47/70\n",
      "305/304 [==============================] - 19s 61ms/step - loss: 0.1261 - acc: 0.9553 - val_loss: 1.2752 - val_acc: 0.7071\n",
      "Epoch 48/70\n",
      "305/304 [==============================] - 19s 63ms/step - loss: 0.1070 - acc: 0.9592 - val_loss: 1.3207 - val_acc: 0.7071\n",
      "Epoch 49/70\n",
      "305/304 [==============================] - 20s 64ms/step - loss: 0.1051 - acc: 0.9631 - val_loss: 1.2433 - val_acc: 0.7238\n",
      "Epoch 50/70\n",
      "305/304 [==============================] - 20s 64ms/step - loss: 0.1065 - acc: 0.9594 - val_loss: 1.4718 - val_acc: 0.6980\n",
      "Epoch 51/70\n",
      "305/304 [==============================] - 19s 62ms/step - loss: 0.1085 - acc: 0.9602 - val_loss: 1.4594 - val_acc: 0.7102\n",
      "Epoch 52/70\n",
      "305/304 [==============================] - 20s 64ms/step - loss: 0.1081 - acc: 0.9574 - val_loss: 1.3648 - val_acc: 0.7162\n",
      "Epoch 53/70\n",
      "305/304 [==============================] - 20s 67ms/step - loss: 0.0970 - acc: 0.9617 - val_loss: 1.2175 - val_acc: 0.7466\n",
      "Epoch 54/70\n",
      "305/304 [==============================] - 21s 69ms/step - loss: 0.1141 - acc: 0.9588 - val_loss: 1.2795 - val_acc: 0.7238\n",
      "Epoch 55/70\n",
      "305/304 [==============================] - 20s 65ms/step - loss: 0.1027 - acc: 0.9613 - val_loss: 1.5936 - val_acc: 0.6950\n",
      "Epoch 56/70\n",
      "305/304 [==============================] - 18s 59ms/step - loss: 0.1109 - acc: 0.9617 - val_loss: 1.3984 - val_acc: 0.7162\n",
      "Epoch 57/70\n",
      "305/304 [==============================] - 18s 60ms/step - loss: 0.1039 - acc: 0.9623 - val_loss: 1.4657 - val_acc: 0.7011\n",
      "Epoch 58/70\n",
      "305/304 [==============================] - 19s 63ms/step - loss: 0.1043 - acc: 0.9582 - val_loss: 1.4913 - val_acc: 0.6995\n",
      "Epoch 59/70\n",
      "305/304 [==============================] - 20s 65ms/step - loss: 0.0954 - acc: 0.9645 - val_loss: 1.6402 - val_acc: 0.6904\n",
      "Epoch 60/70\n",
      "305/304 [==============================] - 19s 63ms/step - loss: 0.0956 - acc: 0.9662 - val_loss: 1.5575 - val_acc: 0.6980\n",
      "Epoch 61/70\n",
      "305/304 [==============================] - 18s 60ms/step - loss: 0.0970 - acc: 0.9672 - val_loss: 1.4419 - val_acc: 0.7056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/70\n",
      "305/304 [==============================] - 18s 58ms/step - loss: 0.0966 - acc: 0.9625 - val_loss: 1.5322 - val_acc: 0.6980\n",
      "Epoch 63/70\n",
      "305/304 [==============================] - 19s 63ms/step - loss: 0.0895 - acc: 0.9676 - val_loss: 1.5431 - val_acc: 0.6950\n",
      "Epoch 64/70\n",
      "305/304 [==============================] - 18s 59ms/step - loss: 0.0939 - acc: 0.9670 - val_loss: 1.5101 - val_acc: 0.6995\n",
      "Epoch 65/70\n",
      "305/304 [==============================] - 18s 60ms/step - loss: 0.0907 - acc: 0.9684 - val_loss: 1.5433 - val_acc: 0.6965\n",
      "Epoch 66/70\n",
      "305/304 [==============================] - 18s 60ms/step - loss: 0.0987 - acc: 0.9648 - val_loss: 1.5635 - val_acc: 0.6935\n",
      "Epoch 67/70\n",
      "305/304 [==============================] - 19s 61ms/step - loss: 0.0819 - acc: 0.9682 - val_loss: 1.5037 - val_acc: 0.7011\n",
      "Epoch 68/70\n",
      "305/304 [==============================] - 18s 60ms/step - loss: 0.0829 - acc: 0.9701 - val_loss: 1.5465 - val_acc: 0.6980\n",
      "Epoch 69/70\n",
      "305/304 [==============================] - 18s 59ms/step - loss: 0.0821 - acc: 0.9711 - val_loss: 1.5208 - val_acc: 0.6980\n",
      "Epoch 70/70\n",
      "305/304 [==============================] - 19s 62ms/step - loss: 0.0812 - acc: 0.9699 - val_loss: 1.5335 - val_acc: 0.6950\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.fit_generator(training_set, steps_per_epoch = TRAIN_IMG_CNT / batch_size, epochs = NUM_EPOCHS,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data = test_set, validation_steps = VALIDATION_CNT / batch_size)\n",
    "model.save_weights('1st_run.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.5\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
